# Awesome-Black-Box-Attacks-in-Adversarial-Examples-
A curated list of awesome black-box attacks in adversarial examples papers, inspired by https://github.com/wangjksjtu/awesome-AML
## Transfer-based Black-box attacks
### Gradient-based methods
Explaining and harnessing adversarial examples[[paper](https://arxiv.org/abs/1412.6572)] [[code](https://github.com/1Konny/FGSM)](white-box)(ICLR2015)    
Adversarial examples in the physical world [[paper](https://arxiv.org/pdf/1607.02533.pdf)] [[code](https://github.com/Harry24k/AEPW-pytorch)](ICLR-workshop2017)     
Boosting adversarial attacks with momentum[[paper](http://arxiv.org/abs/1710.06081v3)] [[code](https://github.com/dongyp13/Non-Targeted-Adversarial-Attacks)](CVPR2018)  
Nesterov accelerated gradient and scale invariance for adversarial attacks[[paper](https://arxiv.org/pdf/1908.06281.pdf)] [[code](https://github.com/JHL-HUST/SI-NI-FGSM)](ICLR2020)  
Enhancing the Transferability of Adversarial Attacks through Variance Tuning[[paper](https://arxiv.org/pdf/2103.15571.pdf)] [[code](https://github.com/JHL-HUST/VT)](CVPR2021)  
Improving transferability of adversarial examples with input diversity[[paper](https://arxiv.org/abs/1803.06978)] [[code](https://github.com/cihangxie/DI-2-FGSM)](CVPR2019)  
Evading defenses to transferable adversarial examples by translation-invariant attacks.[[paper](https://openaccess.thecvf.com/content_CVPR_2019/papers/Dong_Evading_Defenses_to_Transferable_Adversarial_Examples_by_Translation-Invariant_Attacks_CVPR_2019_paper.pdf)] [[code](https://github.com/dongyp13/Translation-Invariant-Attacks)](CVPR2019)

### Optimization-based Methods
## Score-based Black-box Attacks
ZOO: Zeroth Order Optimization Based Black-box Attacks to Deep Neural Networks without Training Substitute Models[[paper](https://arxiv.org/pdf/1708.03999.pdf)] [[code](https://github.com/IBM/ZOO-Attack)](2017)    
Black-box adversarial attacks with limited queries and information[[paper](https://arxiv.org/pdf/1804.08598.pdf)][[code](https://github.com/labsix/limited-blackbox-attacks)](ICML2018)    
Adversarial risk and the dangers of evaluating against weak attacks[[paper](https://arxiv.org/pdf/1802.05666.pdf)](ICLR2018)    
Improving black-box adversarial attacks with a transfer-based prior[[paper](https://arxiv.org/pdf/1906.06919.pdf)][[code](https://github.com/prior-guided-rgf/Prior-Guided-RGF)](NIPS2019)   
NATTACK: Learning the Distributions of Adversarial Examples for an Improved Black-Box Attack on Deep Neural Networks[[paper](https://arxiv.org/pdf/1905.00441.pdf)] [[code](https://github.com/Cold-Winter/Nattack)](ICML2019)   
## Decision-based Black-box Attacks



